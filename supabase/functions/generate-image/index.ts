
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import Replicate from "https://esm.sh/replicate@0.25.2"

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers":
    "authorization, x-client-info, apikey, content-type",
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const REPLICATE_API_KEY = Deno.env.get('REPLICATE_API_KEY')
    if (!REPLICATE_API_KEY) {
      throw new Error('REPLICATE_API_KEY is not set')
    }

    const replicate = new Replicate({
      auth: REPLICATE_API_KEY,
    })

    const body = await req.json()

    // Check if request is complete with required fields
    if (!body.prompt || !body.model) {
      return new Response(
        JSON.stringify({ 
          error: "Missing required fields: prompt and model are required" 
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          status: 400,
        }
      )
    }

    console.log(`Generating image with model: ${body.model}, prompt: ${body.prompt}`)

    let modelId
    let modelConfig

    // Updated model versions with the latest IDs
    switch (body.model) {
      case "sdxl":
        modelId = "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b"
        modelConfig = {
          prompt: body.prompt,
          width: 1024,
          height: 1024,
          num_outputs: 1,
          num_inference_steps: 25,
        }
        break
      case "sdxl-turbo":
        modelId = "stability-ai/sdxl-turbo:3a04a2eeaa4c2ef2cad7cb7ee360b5da01388a1de219b273c81c39e02b3e9996"
        modelConfig = {
          prompt: body.prompt,
          num_outputs: 1,
          num_inference_steps: 1,
          guidance_scale: 0,
        }
        break
      case "dreamshaper":
        modelId = "stability-ai/dreamshaper:620cd8e7a14e62dece9646337812b1cdfcf58d87fad8f2e31adf1ce5a11a2910"
        modelConfig = {
          prompt: body.prompt,
          negative_prompt: "ugly, deformed, disfigured, poor quality, low quality",
          width: 768,
          height: 768,
          num_outputs: 1,
          num_inference_steps: 25,
          guidance_scale: 7.5,
        }
        break
      case "flux":
      default:
        modelId = "black-forest-labs/flux-schnell:e4b7ebac5a94bf1875d572a94ceca594c12d8831e16e41b6e50ab5be53a8e8e2"
        modelConfig = {
          prompt: body.prompt,
          go_fast: true,
          megapixels: "1",
          num_outputs: 1,
          aspect_ratio: "1:1",
          output_format: "webp",
          output_quality: 80,
          num_inference_steps: 4
        }
        break
    }

    // Run the model with better error handling and timeouts
    try {
      // Set max timeout to 60 seconds
      const timeoutPromise = new Promise((_, reject) => {
        setTimeout(() => reject(new Error("Generation timed out after 60 seconds")), 60000);
      });

      // Create the actual generation promise
      const generationPromise = replicate.run(modelId, {
        input: modelConfig
      });

      // Race the promises
      const output = await Promise.race([timeoutPromise, generationPromise]);

      console.log("Generation response:", output);
      
      if (!output || (Array.isArray(output) && output.length === 0)) {
        throw new Error("No output was generated by the model");
      }

      return new Response(JSON.stringify({ output }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200,
      });
    } catch (modelError) {
      console.error("Model error:", modelError);
      
      // If the primary model fails, try falling back to Flux as a more reliable model
      if (body.model !== "flux") {
        console.log("Attempting fallback to Flux model");
        try {
          const fallbackModelId = "black-forest-labs/flux-schnell:e4b7ebac5a94bf1875d572a94ceca594c12d8831e16e41b6e50ab5be53a8e8e2";
          const fallbackConfig = {
            prompt: body.prompt,
            go_fast: true,
            megapixels: "1",
            num_outputs: 1,
            aspect_ratio: "1:1",
            output_format: "webp",
            output_quality: 80,
            num_inference_steps: 4
          };
          
          const fallbackOutput = await replicate.run(fallbackModelId, {
            input: fallbackConfig
          });
          
          if (!fallbackOutput || (Array.isArray(fallbackOutput) && fallbackOutput.length === 0)) {
            throw new Error("No output was generated by the fallback model");
          }
          
          console.log("Fallback generation response:", fallbackOutput);
          return new Response(JSON.stringify({ 
            output: fallbackOutput,
            note: "Used fallback model: flux"
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' },
            status: 200,
          });
        } catch (fallbackError) {
          console.error("Fallback model error:", fallbackError);
          throw new Error(`Primary model failed: ${modelError.message}. Fallback model also failed: ${fallbackError.message}`);
        }
      } else {
        throw modelError;
      }
    }
  } catch (error) {
    console.error("Error in generate-image function:", error);
    
    // More descriptive error response
    let errorMessage = error.message;
    let statusCode = 500;
    
    // Check for specific error types
    if (errorMessage.includes("Invalid version") || errorMessage.includes("not permitted")) {
      errorMessage = "Invalid model version or not permitted. This may be due to outdated model references.";
      statusCode = 422;
    } else if (errorMessage.includes("rate limit")) {
      errorMessage = "Rate limit exceeded. Please try again later.";
      statusCode = 429;
    } else if (errorMessage.includes("unauthorized") || errorMessage.includes("authentication")) {
      errorMessage = "Authentication error. Please check your API key.";
      statusCode = 401;
    } else if (errorMessage.includes("timeout")) {
      errorMessage = "Generation timed out. Please try again with a different model or a simpler prompt.";
      statusCode = 408;
    }
    
    return new Response(JSON.stringify({ 
      error: errorMessage,
      details: error.message
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: statusCode,
    });
  }
})
